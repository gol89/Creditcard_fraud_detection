{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "import dtale\n",
    "import tensorflow as tf\n",
    "\n",
    "#Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#other Libraries\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalaced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.481386e+04</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.165980e-15</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.373150e-15</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>9.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.086869e-15</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>16.875344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.490107e-15</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>73.301626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>120.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.177556e-16</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-2.406455e-15</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>15.594995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.239751e-15</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.673327e-15</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.254995e-15</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.176030e-16</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.662505</td>\n",
       "      <td>7.126883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.206296e-15</td>\n",
       "      <td>0.958596</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.425574</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.913003e-15</td>\n",
       "      <td>0.915316</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.582884</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>8.877742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.437666e-15</td>\n",
       "      <td>0.876253</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-0.468037</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>0.523296</td>\n",
       "      <td>17.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.800113e-16</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.483748</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.572133e-16</td>\n",
       "      <td>0.838176</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.498850</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.039817e-15</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.456299</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.458949</td>\n",
       "      <td>5.591971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>6.406703e-16</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-0.211721</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.656562e-16</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.444850e-16</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.471968e-15</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>4.584549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.687098e-15</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.666453e-16</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>31.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.220404e-16</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.834962e+01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.727486e-03</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std         min           25%  \\\n",
       "Time    284807.0  9.481386e+04  47488.145955    0.000000  54201.500000   \n",
       "V1      284807.0  1.165980e-15      1.958696  -56.407510     -0.920373   \n",
       "V2      284807.0  3.416908e-16      1.651309  -72.715728     -0.598550   \n",
       "V3      284807.0 -1.373150e-15      1.516255  -48.325589     -0.890365   \n",
       "V4      284807.0  2.086869e-15      1.415869   -5.683171     -0.848640   \n",
       "V5      284807.0  9.604066e-16      1.380247 -113.743307     -0.691597   \n",
       "V6      284807.0  1.490107e-15      1.332271  -26.160506     -0.768296   \n",
       "V7      284807.0 -5.556467e-16      1.237094  -43.557242     -0.554076   \n",
       "V8      284807.0  1.177556e-16      1.194353  -73.216718     -0.208630   \n",
       "V9      284807.0 -2.406455e-15      1.098632  -13.434066     -0.643098   \n",
       "V10     284807.0  2.239751e-15      1.088850  -24.588262     -0.535426   \n",
       "V11     284807.0  1.673327e-15      1.020713   -4.797473     -0.762494   \n",
       "V12     284807.0 -1.254995e-15      0.999201  -18.683715     -0.405571   \n",
       "V13     284807.0  8.176030e-16      0.995274   -5.791881     -0.648539   \n",
       "V14     284807.0  1.206296e-15      0.958596  -19.214325     -0.425574   \n",
       "V15     284807.0  4.913003e-15      0.915316   -4.498945     -0.582884   \n",
       "V16     284807.0  1.437666e-15      0.876253  -14.129855     -0.468037   \n",
       "V17     284807.0 -3.800113e-16      0.849337  -25.162799     -0.483748   \n",
       "V18     284807.0  9.572133e-16      0.838176   -9.498746     -0.498850   \n",
       "V19     284807.0  1.039817e-15      0.814041   -7.213527     -0.456299   \n",
       "V20     284807.0  6.406703e-16      0.770925  -54.497720     -0.211721   \n",
       "V21     284807.0  1.656562e-16      0.734524  -34.830382     -0.228395   \n",
       "V22     284807.0 -3.444850e-16      0.725702  -10.933144     -0.542350   \n",
       "V23     284807.0  2.578648e-16      0.624460  -44.807735     -0.161846   \n",
       "V24     284807.0  4.471968e-15      0.605647   -2.836627     -0.354586   \n",
       "V25     284807.0  5.340915e-16      0.521278  -10.295397     -0.317145   \n",
       "V26     284807.0  1.687098e-15      0.482227   -2.604551     -0.326984   \n",
       "V27     284807.0 -3.666453e-16      0.403632  -22.565679     -0.070840   \n",
       "V28     284807.0 -1.220404e-16      0.330083  -15.430084     -0.052960   \n",
       "Amount  284807.0  8.834962e+01    250.120109    0.000000      5.600000   \n",
       "Class   284807.0  1.727486e-03      0.041527    0.000000      0.000000   \n",
       "\n",
       "                 50%            75%            max  \n",
       "Time    84692.000000  139320.500000  172792.000000  \n",
       "V1          0.018109       1.315642       2.454930  \n",
       "V2          0.065486       0.803724      22.057729  \n",
       "V3          0.179846       1.027196       9.382558  \n",
       "V4         -0.019847       0.743341      16.875344  \n",
       "V5         -0.054336       0.611926      34.801666  \n",
       "V6         -0.274187       0.398565      73.301626  \n",
       "V7          0.040103       0.570436     120.589494  \n",
       "V8          0.022358       0.327346      20.007208  \n",
       "V9         -0.051429       0.597139      15.594995  \n",
       "V10        -0.092917       0.453923      23.745136  \n",
       "V11        -0.032757       0.739593      12.018913  \n",
       "V12         0.140033       0.618238       7.848392  \n",
       "V13        -0.013568       0.662505       7.126883  \n",
       "V14         0.050601       0.493150      10.526766  \n",
       "V15         0.048072       0.648821       8.877742  \n",
       "V16         0.066413       0.523296      17.315112  \n",
       "V17        -0.065676       0.399675       9.253526  \n",
       "V18        -0.003636       0.500807       5.041069  \n",
       "V19         0.003735       0.458949       5.591971  \n",
       "V20        -0.062481       0.133041      39.420904  \n",
       "V21        -0.029450       0.186377      27.202839  \n",
       "V22         0.006782       0.528554      10.503090  \n",
       "V23        -0.011193       0.147642      22.528412  \n",
       "V24         0.040976       0.439527       4.584549  \n",
       "V25         0.016594       0.350716       7.519589  \n",
       "V26        -0.052139       0.240952       3.517346  \n",
       "V27         0.001342       0.091045      31.612198  \n",
       "V28         0.011244       0.078280      33.847808  \n",
       "Amount     22.000000      77.165000   25691.160000  \n",
       "Class       0.000000       0.000000       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "#all the features are numeric in nature\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genuine Transactions 99.83 % of the Dataset\n",
      "Fraud Transactions 0.17 % of the Dataset\n"
     ]
    }
   ],
   "source": [
    "#The Target class is heavily skewed\n",
    "print('Genuine Transactions',round(df['Class'].value_counts()[0]/len(df)*100,2), '% of the Dataset')\n",
    "print('Fraud Transactions',round(df['Class'].value_counts()[1]/len(df)*100,2), '% of the Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Genuine vs Fraud Transactions')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot('Class',data=df)\n",
    "plt.title('Genuine vs Fraud Transactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliiting the Dataset into Train and test before analysing it further\n",
    "X = df.drop('Class',axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227845, 30), (56962, 30), (227845,), (56962,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genuine Transactions in train set 99.83 % of the Dataset\n",
      "Genuine Transactions in test set 99.83 % of the Dataset\n",
      "Fraud Transactions in train set 0.17 % of the Dataset\n",
      "Fraud Transactions in test set 0.17 % of the Dataset\n"
     ]
    }
   ],
   "source": [
    "#Poportion of Genuine and fraud transactions in training and test set\n",
    "print('Genuine Transactions in train set',round((len(y_train) - sum(y_train))/len(y_train)*100,2), '% of the Dataset')\n",
    "print('Genuine Transactions in test set',round((len(y_test) - sum(y_test))/len(y_test)*100,2), '% of the Dataset')\n",
    "\n",
    "print('Fraud Transactions in train set',round(sum(y_train)/len(y_train)*100,2), '% of the Dataset')\n",
    "print('Fraud Transactions in test set',round(sum(y_test)/len(y_test)*100,2), '% of the Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataset is split in to train and test set.\n",
    "#We can further analzye the data and/or up/down sample the data to fit to our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"475\"\n",
       "            src=\"http://DESKTOP-37B1VED:40000/dtale/iframe/1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x24212eb0eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Dtale for exploratory data analyses\n",
    "dtale.show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(corr,cmap='coolwarm_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before we upsample the data let us try some classifiers and see how they perform\n",
    "classifiers = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"KNearest\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classifier\":SVC(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers:  LogisticRegression has a training score of  100.0 % accuracy score\n",
      "Classifiers:  KNeighborsClassifier has a training score of  100.0 % accuracy score\n",
      "Classifiers:  SVC has a training score of  100.0 % accuracy score\n"
     ]
    }
   ],
   "source": [
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train,y_train)\n",
    "    training_score = cross_val_score(classifier,X_train,y_train,cv=5)\n",
    "    print('Classifiers: ', classifier.__class__.__name__, \"has a training score of \", round(training_score.mean(),2)*100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it can be seen that all the classifiers are giving a score of 100 percent \n",
    "#let us select one of them and see if it correctly predicts the fraudelent transaction or not\n",
    "y_train.sum()\n",
    "#there are 394 fradulent transactions in training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       0.72      0.68      0.70       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.86      0.84      0.85    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "[[227348    103]\n",
      " [   128    266]]\n"
     ]
    }
   ],
   "source": [
    "pred = log_reg.predict(X_train)\n",
    "print(classification_report(y_train,pred))\n",
    "print(confusion_matrix(y_train,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus it can be seen that the model is not that good and is missing most of the fradulent transactions even on the training set that it has already seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227845, 30), (56962, 30))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227451\n",
      "           1       1.00      1.00      1.00       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       1.00      1.00      1.00    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "[[227451      0]\n",
      " [     1    393]]\n"
     ]
    }
   ],
   "source": [
    "#checking for random forest \n",
    "rnd = RandomForestClassifier()\n",
    "rnd.fit(X_train,y_train)\n",
    "pred = rnd.predict(X_train)\n",
    "print(classification_report(y_train,pred))\n",
    "print(confusion_matrix(y_train,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962, 30)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.94      0.82      0.87        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.91      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56859     5]\n",
      " [   18    80]]\n"
     ]
    }
   ],
   "source": [
    "pred1 = rnd.predict(X_test)\n",
    "print(classification_report(y_test,pred1))\n",
    "print(confusion_matrix(y_test,pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can downsample or upsample the data to make it balanced and then check the models performance.\n",
    "We would go for upsampling the data rather than downsampling since valuable information is lost in undersampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While oversampling and using cross validation care must be taken. The oversampling should not be applied before cross validation as the samples in the validation dataset will already be present in the train dataset and thus will lead to overfitting due to Data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X (train): 227845 | Length of y (train): 227845\n",
      "Length of X (test): 56962 | Length of y (test): 56962\n"
     ]
    }
   ],
   "source": [
    "print('Length of X (train): {} | Length of y (train): {}'.format(len(X_train), len(y_train)))\n",
    "print('Length of X (test): {} | Length of y (test): {}'.format(len(X_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will append the scores to the list and then find the average\n",
    "precision_lst = []\n",
    "recall_lst = []\n",
    "f1_lst = []\n",
    "auc_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 17:19:10,053 - INFO     - Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing shutdown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 17:19:14,479 - INFO     - Executing shutdown...\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.1, 1, 10]}\n",
    "rand_log_reg = RandomizedSearchCV(log_reg,log_reg_params,n_iter=5)\n",
    "\n",
    "#Implementing SMOTE for up sampling during cross validation.\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "for train_index , test_index in sss.split(X_train,y_train):\n",
    "    pipeline = imbalaced_make_pipeline(SMOTE(sampling_strategy='minority'),rand_log_reg)\n",
    "            \n",
    "    #we have the index for the training and the test dataset, now we will apply the SMOTE (upsampling) only on the test indexes\n",
    "    model = pipeline.fit(X_train.iloc[train_index],y_train.iloc[train_index])\n",
    "    best_est = rand_log_reg.best_estimator_\n",
    "    prediction = best_est.predict(X_train.iloc[test_index])\n",
    "    \n",
    "    precision_lst.append(precision_score(y_train.iloc[test_index],prediction))\n",
    "    recall_lst.append(recall_score(y_train.iloc[test_index],prediction))\n",
    "    f1_lst.append(f1_score(y_train.iloc[test_index],prediction))\n",
    "    auc_lst.append(roc_auc_score(y_train.iloc[test_index],prediction))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.06469464352708341\n",
      "recall: 0.8888888888888888\n",
      "f1: 0.12040325545019945\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
    "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
    "print(\"f1: {}\".format(np.mean(f1_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.042921204356181936, 0.044382801664355064, 0.07553191489361702, 0.07027540360873694, 0.06820365033621517, 0.07925407925407925, 0.06824644549763033, 0.07088122605363985, 0.06255506607929516]\n",
      "[0.8481012658227848, 0.810126582278481, 0.8987341772151899, 0.9367088607594937, 0.8987341772151899, 0.8607594936708861, 0.9113924050632911, 0.9367088607594937, 0.8987341772151899]\n",
      "[0.08170731707317073, 0.084155161078238, 0.1393523061825319, 0.13074204946996468, 0.12678571428571428, 0.14514407684098185, 0.12698412698412698, 0.13178984861976847, 0.1169686985172982]\n"
     ]
    }
   ],
   "source": [
    "print(precision_lst)\n",
    "print(recall_lst)\n",
    "print(f1_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Fraud       1.00      0.98      0.99     56864\n",
      "       Fraud       0.06      0.91      0.12        98\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.53      0.94      0.55     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = ['No Fraud', 'Fraud']\n",
    "smote_prediction = best_est.predict(X_test)\n",
    "print(classification_report(y_test, smote_prediction, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55548  1316]\n",
      " [    9    89]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,smote_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus it can be seen that a lot of normal transactions are being classified as fradulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Precision Recall Curve')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_score = best_est.decision_function(X_test)\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "plt.step(recall, precision, color='r', alpha=0.2)\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,color='#F59B00')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision Recall Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a function for the upsampling using SMOTE and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_cross_val(X_train,y_train,X_test,y_test,algo):\n",
    "    sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    for train_index , test_index in sss.split(X_train,y_train):\n",
    "        pipeline = imbalaced_make_pipeline(SMOTE(sampling_strategy='minority'),algo)\n",
    "\n",
    "        #we have the index for the training and the test dataset, now we will apply the SMOTE (upsampling) only on the test indexes\n",
    "        model = pipeline.fit(X_train.iloc[train_index],y_train.iloc[train_index])\n",
    "        best_est = algo.best_estimator_\n",
    "        print(algo.best_estimator_)\n",
    "        prediction = best_est.predict(X_train.iloc[test_index])\n",
    "\n",
    "        precision_lst.append(precision_score(y_train.iloc[test_index],prediction))\n",
    "        recall_lst.append(recall_score(y_train.iloc[test_index],prediction))\n",
    "        f1_lst.append(f1_score(y_train.iloc[test_index],prediction))\n",
    "        auc_lst.append(roc_auc_score(y_train.iloc[test_index],prediction))\n",
    "        \n",
    "    print(\"precision: {}\".format(np.mean(precision_lst)))\n",
    "    print(\"recall: {}\".format(np.mean(recall_lst)))\n",
    "    print(\"f1: {}\".format(np.mean(f1_lst)))\n",
    "    \n",
    "    labels = ['No Fraud', 'Fraud']\n",
    "    smote_prediction = best_est.predict(X_test)\n",
    "    print('Classification report for the best estimator')\n",
    "    print(classification_report(y_test, smote_prediction, target_names=labels))\n",
    "    print('Confusion matirx for the best estimator')\n",
    "    print(confusion_matrix(y_test,smote_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "svc_params = {'C': [0.1, 1, 10]}\n",
    "rand_svc = RandomizedSearchCV(svc,svc_params,n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_cross_val(X_train,y_train,X_test,y_test,rand_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above two cells are not evaluated as they take too long to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((454902, 30), (227845, 30))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(sampling_strategy='minority',random_state=42)\n",
    "X_trainsm, y_trainsm = sm.fit_sample(X_train,y_train)\n",
    "X_trainsm.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, n_jobs=-1, oob_score=True, verbose=1,\n",
       "                       warm_start=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(bootstrap=True,oob_score=True,warm_start=True,verbose=1,max_depth=15,n_jobs=-1)\n",
    "forest.fit(X_trainsm,y_trainsm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],columns=['Feature Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp['Feature Importances'] = forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Feature Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>V14</td>\n",
       "      <td>0.261268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>V10</td>\n",
       "      <td>0.103201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V12</td>\n",
       "      <td>0.091756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V4</td>\n",
       "      <td>0.091629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V11</td>\n",
       "      <td>0.076397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature Name  Feature Importances\n",
       "14          V14             0.261268\n",
       "10          V10             0.103201\n",
       "12          V12             0.091756\n",
       "4            V4             0.091629\n",
       "11          V11             0.076397"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.sort_values('Feature Importances',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "forest_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.70      0.87      0.77        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.85      0.93      0.89     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56827    37]\n",
      " [   13    85]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(n_jobs=-1, oob_score=True,\n",
       "                                              random_state=42, verbose=1,\n",
       "                                              warm_start=True),\n",
       "             param_grid={'max_depth': [15, 18, 20],\n",
       "                         'min_samples_leaf': [3, 5, 7]})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_grid = RandomForestClassifier(n_estimators=100,oob_score=True,warm_start=True,verbose=1,random_state=42,n_jobs=-1)\n",
    "forest_params = {\"max_depth\": [15,18,20], 'min_samples_leaf': [3,5,7]}\n",
    "forest_random = GridSearchCV(forest_grid,forest_params)\n",
    "\n",
    "forest_random.fit(X_trainsm,y_trainsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, min_samples_leaf=3, n_jobs=-1,\n",
       "                       oob_score=True, random_state=42, verbose=1,\n",
       "                       warm_start=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998461206062681"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 76.16487117,  78.57608185,  79.11582775,  85.43729262,\n",
       "         84.81033864,  83.43027325, 190.09305153, 191.80567737,\n",
       "        206.16860833]),\n",
       " 'std_fit_time': array([0.97861595, 2.09488578, 1.42988697, 1.73500328, 0.73221569,\n",
       "        1.97315156, 6.33857934, 2.60373966, 8.27756156]),\n",
       " 'mean_score_time': array([0.27592068, 0.3074039 , 0.30486221, 0.32171459, 0.31794009,\n",
       "        0.29619813, 0.88463631, 0.9690105 , 1.047405  ]),\n",
       " 'std_score_time': array([0.01444644, 0.02877635, 0.03954398, 0.03858671, 0.02472401,\n",
       "        0.01367707, 0.06864407, 0.05582332, 0.2341039 ]),\n",
       " 'param_max_depth': masked_array(data=[15, 15, 15, 18, 18, 18, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[3, 5, 7, 3, 5, 7, 3, 5, 7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 15, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 15, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 15, 'min_samples_leaf': 7},\n",
       "  {'max_depth': 18, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 18, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 18, 'min_samples_leaf': 7},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 7}],\n",
       " 'split0_test_score': array([0.99970323, 0.9996263 , 0.9996153 , 0.99981315, 0.99979117,\n",
       "        0.99973621, 0.99984612, 0.99981315, 0.99976918]),\n",
       " 'split1_test_score': array([0.99980216, 0.9996153 , 0.99978017, 0.99985711, 0.9998681 ,\n",
       "        0.99985711, 0.99989009, 0.9998681 , 0.99984612]),\n",
       " 'split2_test_score': array([0.99970323, 0.99963728, 0.99953836, 0.99978017, 0.99975819,\n",
       "        0.99973621, 0.99980215, 0.99978017, 0.99971422]),\n",
       " 'split3_test_score': array([0.99962629, 0.99971422, 0.99962629, 0.99980215, 0.99984612,\n",
       "        0.99976918, 0.9998681 , 0.9998681 , 0.99984612]),\n",
       " 'split4_test_score': array([0.99973621, 0.99967026, 0.99968125, 0.99980215, 0.99979116,\n",
       "        0.99975819, 0.99982414, 0.99980215, 0.99978017]),\n",
       " 'mean_test_score': array([0.99971422, 0.99965267, 0.99964828, 0.99981095, 0.99981095,\n",
       "        0.99977138, 0.99984612, 0.99982634, 0.99979116]),\n",
       " 'std_test_score': array([5.69017512e-05, 3.58514630e-05, 8.01700780e-05, 2.54475979e-05,\n",
       "        4.01753170e-05, 4.47286357e-05, 3.10887911e-05, 3.57180964e-05,\n",
       "        5.01287667e-05]),\n",
       " 'rank_test_score': array([7, 8, 9, 4, 3, 6, 1, 2, 5])}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_random.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "forest_pred_grid = forest_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.77      0.87      0.82        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.89      0.93      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,forest_pred_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56839    25]\n",
      " [   13    85]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,forest_pred_grid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
